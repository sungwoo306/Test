/home/paul/mambaforge/envs/qtc/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:578: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.
  rank_zero_deprecation(
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/paul/mambaforge/envs/qtc/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
/home/paul/mambaforge/envs/qtc/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
  warning_cache.warn(
{"BasicBlock": "type", "CIFAR10": "type", "DataLoader": "type", "F": "module", "MNIST": "type", "M_ResNet18": "function", "ModelCheckpoint": "type", "ResNet": "type", "ResNet18": "function", "ResNetWrapperBasic": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "ckpt_best": "ModelCheckpoint", "get_ipython": "function", "logger": "WandbLogger", "optim": "module", "os": "module", "pl": "module", "random_seed": "int", "testloader": "DataLoader", "testset": "CIFAR10", "torch": "module", "trainer": "Trainer", "trainloader": "DataLoader", "trainset": "CIFAR10", "transform": "Compose", "transforms": "module"}
{"BasicBlock": "type", "CIFAR10": "type", "DataLoader": "type", "F": "module", "MNIST": "type", "M_ResNet18": "function", "ModelCheckpoint": "type", "ResNet": "type", "ResNet18": "function", "ResNetWrapperBasic": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "ckpt_best": "ModelCheckpoint", "get_ipython": "function", "logger": "WandbLogger", "optim": "module", "os": "module", "pl": "module", "random_seed": "int", "testloader": "DataLoader", "testset": "CIFAR10", "torch": "module", "trainer": "Trainer", "trainloader": "DataLoader", "trainset": "CIFAR10", "transform": "Compose", "transforms": "module"}
/home/paul/mambaforge/envs/qtc/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.
  rank_zero_warn("You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.")
  | Name  | Type   | Params
---------------------------------
0 | model | ResNet | 4.9 M
---------------------------------
4.9 M     Trainable params
0         Non-trainable params
4.9 M     Total params
19.613    Total estimated model params size (MB)
/home/paul/mambaforge/envs/qtc/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/mnt/c/Users/홍성우/Desktop/Projects/Test/cifar10/models/resnet.py:123: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(out)




Epoch 0:   2%|▏         | 27/1563 [00:08<08:20,  3.07it/s, loss=2.12, v_num=6]
/home/paul/mambaforge/envs/qtc/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
Epoch 0:   2%|▏         | 29/1563 [00:09<08:17,  3.08it/s, loss=2.11, v_num=6]{"BasicBlock": "type", "CIFAR10": "type", "DataLoader": "type", "F": "module", "MNIST": "type", "M_ResNet18": "function", "ModelCheckpoint": "type", "ResNet": "type", "ResNet18": "function", "ResNetWrapperBasic": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "ckpt_best": "ModelCheckpoint", "get_ipython": "function", "lightning_model": "ResNetWrapperBasic", "logger": "WandbLogger", "optim": "module", "os": "module", "pl": "module", "random_seed": "int", "testloader": "DataLoader", "testset": "CIFAR10", "torch": "module", "trainer": "Trainer", "trainloader": "DataLoader", "trainset": "CIFAR10", "transform": "Compose", "transforms": "module"}
{"BasicBlock": "type", "CIFAR10": "type", "DataLoader": "type", "F": "module", "MNIST": "type", "M_ResNet18": "function", "ModelCheckpoint": "type", "ResNet": "type", "ResNet18": "function", "ResNetWrapperBasic": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "ckpt_best": "ModelCheckpoint", "get_ipython": "function", "lightning_model": "ResNetWrapperBasic", "logger": "WandbLogger", "optim": "module", "os": "module", "pl": "module", "random_seed": "int", "testloader": "DataLoader", "testset": "CIFAR10", "torch": "module", "trainer": "Trainer", "trainloader": "DataLoader", "trainset": "CIFAR10", "transform": "Compose", "transforms": "module"}
